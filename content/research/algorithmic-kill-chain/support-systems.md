+++
date = '2026-01-26'
draft = false
title = 'The Machine Behind the Machine: Digital Infrastructure for Automated Killing'
summary = "Project Nimbus, Pegasus spyware, and the corporate infrastructure enabling algorithmic violence"
series = ['The Algorithmic Kill Chain']
series_order = 5
toc = true
+++

## The Numbers

**$1.2 billion** — Value of Project Nimbus, the Google-Amazon cloud contract providing AI infrastructure to the Israeli military

**100 billion words** — Volume of intercepted Palestinian communications used to train Unit 8200's surveillance language model

**6** — Palestinian human rights defenders confirmed hacked by Pegasus spyware before Israel designated their organizations as "terrorist"

**28+** — Google and Amazon workers fired for protesting Project Nimbus

**"Seconds rather than minutes"** — Fire Weaver's sensor-to-shooter acceleration, per Rafael marketing materials

**$33 million** — RTX-Rafael facility in Camden, Arkansas producing Iron Dome missiles

---

The targeting systems documented in this series—[Gospel](/research/algorithmic-kill-chain/gospel/), [Lavender](/research/algorithmic-kill-chain/lavender/), and [Where's Daddy?](/research/algorithmic-kill-chain/wheres-daddy/)—do not operate in isolation. They depend on a vast supporting infrastructure: cloud computing platforms that process surveillance data, decision support systems that translate AI recommendations into bombing raids, spyware that penetrates the devices of human rights defenders, and language models trained on the intercepted conversations of an occupied population.

This infrastructure is not incidental. It is the foundation upon which automated warfare operates. Without Google and Amazon cloud services, the machine learning systems identifying targets could not function at scale. Without Fire Factory, AI-generated target lists would remain abstractions rather than scheduled airstrikes. Without Pegasus, the intelligence apparatus would lose its capacity to monitor those documenting its crimes.

The corporations and state agencies building this infrastructure are not passive contractors. They are architects of a system designed to surveil, target, and eliminate.

---

## The Support Ecosystem

| System | Function | Developer | Kill Chain Role |
|:-------|:---------|:----------|:----------------|
| **Fire Factory** | Automated strike planning | IDF/Israeli contractors | Converts Lavender/Gospel target lists into bombing schedules |
| **Fire Weaver** | Sensor-to-shooter network | Rafael | Accelerates engagement from identification to strike |
| **Alchemist** | Real-time threat alerting | IDF | Feeds intelligence to Fire Factory and field commanders |
| **Depth of Wisdom** | Tunnel network mapping | IDF | Provides targeting data for subterranean infrastructure |
| **Edge 360** | Vehicle threat detection | Elbit Systems | Platform-level AI for armored vehicles |
| **Project Nimbus** | Cloud infrastructure/AI | Google, Amazon | Powers Gospel, Lavender, and mass data processing |
| **Pegasus** | Device infiltration spyware | NSO Group | Targets human rights defenders monitoring abuses |
| **Unit 8200 LLM** | Surveillance language model | IDF Unit 8200 | Analyzes intercepted communications for "incrimination" |

---

## Fire Factory: The Mass Assassination Scheduler

Fire Factory transforms AI-generated target lists into operational bombing campaigns. Taking outputs from systems like Gospel (structural targets) and Lavender (individual targets), it calculates required munition loads, prioritizes targets, assigns specific targets to aircraft and drones, and proposes attack schedules.

The system functions as logistical infrastructure for aerial bombardment at industrial scale. As one intelligence source described the Gaza operations: a "mass assassination factory."

Dr. Tal Mimran, a legal scholar who has studied these systems, describes the operational flow:

> "Fire Factory evaluates and categorizes information into possible threats or targets, acting as a bridge between data collection [Alchemist] and target selection [Gospel]."

The system reportedly processes "military-approved targets"—but the nature of AI target generation means Fire Factory schedules strikes based on data from systems like Lavender, which intelligence sources say operated with a documented error rate and permissive rules of engagement accepting up to 20 civilian casualties per junior militant.

Fire Factory may incorporate automated Rules of Engagement and Collateral Damage Estimation calculations. The reliability and ethical thresholds embedded within these assessments remain opaque. What is observable is output: the systematic bombardment of residential buildings, the destruction of entire neighborhoods, the "where's daddy?" timing of strikes to maximize deaths when families gather.

The system's lack of direct connection to deployed weapons does not insulate it from responsibility. It is the crucial node translating algorithmic recommendations into kinetic action—the scheduler that turns probability scores into scheduled destruction.

---

## Fire Weaver: Killing in Seconds

Developed by Rafael in collaboration with the Israeli Ministry of Defense, Fire Weaver is a networked "sensor-to-shooter" system designed for battalion-level operations and below. It connects sensors—drone feeds, observation posts, targeting systems—directly to weapons platforms using AI algorithms that process battlefield data in real-time.

The purpose is explicit: drastically shorten the time between target identification and engagement.

Rafael's marketing materials promise attacks "in seconds, rather than minutes."

Fire Weaver analyzes targets shared across its network, calculating the "optimal shooter" based on location, line-of-sight, weapon effectiveness, and ammunition status. It uses a GPS-independent "geo-pixel" coordinate system ensuring all networked units view identical target data, displaying targets and friendly forces through augmented reality overlays on weapon sights and battle management systems.

The system's integration with Gospel and Lavender extends automation down to the tactical level. Where Fire Factory schedules bombing campaigns, Fire Weaver accelerates individual engagements—reducing the time available for human deliberation, collapsing the distance between algorithmic identification and lethal force.

Rafael has signed agreements to integrate Fire Weaver with Safran's Moskito TI target locators, embedding the system deeper into international military hardware ecosystems. The company markets these capabilities globally, using Gaza as a proving ground for technologies sold to militaries worldwide.

---

## Alchemist and Depth of Wisdom: The Intelligence Layer

These AI systems were deployed alongside Gospel during Israel's 2021 assault on Gaza—what military officials dubbed the "first AI war."

**Alchemist** analyzes incoming data streams and alerts troops to possible threats in real-time, feeding information directly to field commanders via handheld devices. It functions as the collection component in the kill chain, processing signals intelligence, surveillance feeds, and geospatial data into actionable intelligence that flows to Fire Factory for evaluation and targeting.

**Depth of Wisdom** maps Gaza's tunnel network, analyzing data to determine tunnel depths, routes, and structural characteristics. This provides targeting intelligence for infrastructure that Israel claims serves military purposes—but which also includes tunnels used for civilian movement and commerce under a 17-year blockade that restricts surface transit.

These systems exemplify AI's role in processing vast intelligence streams to provide battlefield awareness. They convert raw surveillance into the structured data that targeting systems consume, contributing to the IDF's claimed situational awareness within Gaza's dense urban environment.

---

## Edge 360: Platform-Level Automation

Edge 360, associated with Elbit Systems, provides algorithmic threat detection for armored vehicles including the Namer and Eitan APCs. Operating in urban environments, it uses sensors to automatically identify potential threats—anti-tank teams, RPG positions—augmenting crew situational awareness and potentially cueing defensive systems.

The system represents AI integration at the platform level: individual combat vehicles carrying their own automated threat assessment. Edge 360 contributes to the survivability of Israeli military assets operating within Palestinian territory while extending algorithmic decision-making to the granular level of individual vehicle operations.

Elbit Systems markets Edge 360 alongside its drone systems, electronic warfare capabilities, and the Hermes UAVs documented in strikes across Gaza. The company's products form a substantial portion of the hardware infrastructure through which Israeli military operations execute.

---

## Project Nimbus: The Cloud Powering the Kill Chain

Project Nimbus is a $1.2 billion contract awarded in 2021, establishing a strategic partnership between the Israeli state—including its military and "defense establishment"—and two of the world's largest technology corporations: Google (Alphabet) and Amazon (AWS).

The contract provides comprehensive cloud computing infrastructure, data storage, and advanced AI/ML capabilities. This is not abstract "cloud services." It is the computational foundation enabling the systems documented throughout this series.

### What Nimbus Provides

Leaked documents and investigative reporting indicate Google and Amazon are supplying:

- Advanced AI/ML suites and data analysis tools
- Facial recognition capabilities
- Object tracking systems
- Potentially emotion recognition and biometric analysis
- Secure, localized cloud instances within Israel's borders

These capabilities allow Israeli authorities to process the vast surveillance data collected on Palestinians—the inputs that feed Gospel, Lavender, and the Unit 8200 language model. Israeli intelligence has reportedly integrated Google Photos into facial recognition systems used for surveillance and arrests in Gaza.

The cloud infrastructure enables large-scale data analysis, AI model training, and database hosting with minimal oversight from the companies themselves. Beyond direct military applications, Nimbus services are used by entities like the Israel Land Authority and the state-owned water company Mekorot—institutions implicated in discriminatory practices regarding land confiscation, settlement expansion, and resource control.

### Corporate Complicity and Worker Resistance

The #NoTechForApartheid campaign, comprised of workers within Google and Amazon, has centered Project Nimbus in demands for corporate accountability. Their argument aligns with findings from Human Rights Watch and Amnesty International: by providing these tools, the corporations directly aid Israel's commission of international crimes.

Worker actions have included:

- Protests and sit-ins occupying executive offices
- Petitions signed by thousands of employees
- Public denunciation of corporate complicity
- Whistleblowing about contract details

Corporate response has been dismissive and punitive. Google maintains the contract is not directed at "highly sensitive, classified, or military workloads relevant to weapons or intelligence services"—a claim contradicted by Israeli government statements and documented military use of cloud services.

Both companies have retaliated against protesting workers. **Twenty-eight employees were fired** following sit-ins and demonstrations organized by No Tech For Apartheid. The firings demonstrate a deliberate choice to protect contracts over ethical responsibility, prioritizing profit from a regime engaged in systematic violence.

---

## Pegasus: Surveillance as Counter-Accountability

Pegasus, developed by Israeli cyber-arms firm NSO Group, represents the surveillance apparatus's reach into the most private digital spaces of those documenting its crimes. Marketed for fighting crime and terrorism, it has been systematically deployed against Palestinian human rights defenders, journalists, lawyers, and activists.

### Technical Capabilities

Pegasus is designed for covert, remote installation on iOS and Android devices using sophisticated "zero-click" exploits requiring no target interaction. Exploits like FORCEDENTRY leveraged vulnerabilities in iMessage to gain complete device control simply by sending a message.

Once installed, Pegasus grants attackers:

- Access to all messages, including encrypted communications
- Email, photos, contacts, call logs, browsing history
- Precise location data
- Remote activation of microphone and camera

The device becomes a surveillance tool monitoring not only the target but everyone they communicate with—creating a chilling effect on activism, journalism, and legal defense work.

### Targeting Palestinian Human Rights Defenders

In late 2021, Front Line Defenders, Citizen Lab, and Amnesty International's Security Lab documented Pegasus infections on phones belonging to six prominent Palestinian human rights defenders:

- **Ghassan Halaika** — Field researcher for Al-Haq (hacked July 2020)
- **Ubai Al-Aboudi** — U.S. citizen, Executive Director of Bisan Center for Research and Development (hacked February 2021)
- **Salah Hammouri** — French-Palestinian lawyer for Addameer Prisoner Support and Human Rights Association (hacked April 2021)
- Three additional defenders who chose to remain anonymous

These hacks occurred before and around the time Israel designated these same six civil society organizations—Al-Haq, Addameer, Bisan Center, Defense for Children International-Palestine, Union of Agricultural Work Committees, Union of Palestinian Women's Committees—as "terrorist organizations" in October 2021.

The timing is not coincidental. Surveillance was used to gather information supporting the designations—a move widely condemned as an attack on Palestinian civil society and an attempt to suppress human rights monitoring.

Subsequent investigations revealed Pegasus targeting of Palestinian-American journalist Daoud Kuttab multiple times between 2022 and 2023.

### State Licensing

Pegasus export is explicitly subject to licensing by the Israeli Ministry of Defense, establishing a direct link between the state and proliferation of this repressive technology. The licensing regime underscores the strategic use of cyber-surveillance as an instrument of Israeli statecraft.

The U.S. government blacklisted NSO Group in November 2021 for facilitating transnational repression. Israel continues to oversee its operations. Pegasus is not merely a private company's product—it is an extension of the Israeli state's surveillance apparatus, deployed against Palestinians and exported globally as a tool of control.

---

## Unit 8200 LLM: Training AI on the Language of the Occupied

The Israeli military's intelligence apparatus—specifically the elite cyber warfare Unit 8200—is developing an AI tool based on Large Language Model technology, similar to ChatGPT. This represents a significant escalation: moving beyond target identification toward analyzing and potentially manipulating the language and communication of the Palestinian population.

### Training Data: 100 Billion Words of Intercepted Conversations

Unlike publicly available LLMs trained on internet data, Unit 8200's model is being fed vast quantities of intercepted Palestinian communications—millions of telephone conversations and text messages captured through Israel's pervasive surveillance infrastructure.

> Sources indicate the model was trained on as much as **100 billion words of Arabic**, including everyday, personal conversations with no inherent intelligence value, harvested specifically because they provide rich data on spoken dialects unavailable elsewhere.

This mass interception and instrumentalization of private communications from an occupied population—not suspected of any crime—constitutes a severe violation of fundamental privacy and digital rights.

### Applications: Prediction, Incrimination, Control

The Unit 8200 LLM is designed to:

- Rapidly process surveillance data to "answer questions" about individuals
- Generate summaries of relationships, activities, and sentiments from private communications
- Identify keywords or expressions of dissent ("troublemaking" words)
- Accelerate identification of individuals for incrimination and arrest

Intelligence sources explicitly state that such AI tools amplify state power, enabling broader population control by facilitating the tracking of human rights activists, monitoring construction in Area C, and providing deeper insight into the lives of Palestinians under occupation.

Unit 8200 already utilizes smaller language models for classification, transcription, and translation—systems that sources say have deepened control and increased arrests by allowing commanders access to translated intelligence without Arabic language skills. The new, larger LLM scales these capabilities dramatically.

### Corporate Expertise

The involvement of Israeli military reservists possessing expertise gained at **Google, Meta, and Microsoft** in developing this LLM raises serious questions about tech industry complicity in building surveillance tools. These companies have employed individuals who subsequently contribute specialized knowledge to systems designed for population control and incrimination.

An LLM trained predominantly on the language of a population living under decades of military occupation is likely to internalize and reproduce biases, misinterpreting cultural expressions, frustration, or political dissent as indicators of threat. As Human Rights Watch notes, LLMs function like "guessing machines"—and their inherent errors, coupled with user over-trust, create significant risks of misidentification and wrongful incrimination.

---

## The Integrated Architecture

These systems do not operate independently. They form an integrated, mutually reinforcing ecosystem designed to maximize surveillance, control, and the application of lethal force.

**Project Nimbus** serves as the foundational layer—providing computational power, data storage, and AI/ML tools. The massive datasets generated by surveillance infrastructure require scalable cloud services for storage, processing, and analysis. This infrastructure enables Gospel, Lavender, and the Unit 8200 LLM.

**Intelligence gathering**—through Pegasus compromising individual devices, mass interception feeding the Unit 8200 LLM, and conventional surveillance—flows into the broader intelligence pool.

**AI systems** (Alchemist, Gospel, Lavender) process this intelligence, identifying threats, generating targets, and detecting patterns.

**Fire Factory** takes AI-generated target lists and automates bombardment logistics—calculating munitions, scheduling strikes.

**Fire Weaver** connects sensors directly to shooters at the tactical level, accelerating engagement based on real-time data.

**Edge 360** provides platform-level threat detection for vehicles operating within this environment.

The result is a cycle: surveillance feeds AI analysis, which directs and accelerates military action, enabled by corporate cloud infrastructure. The components are interdependent. Remove the cloud computing and the AI systems cannot operate at scale. Remove the targeting systems and the decision support tools have nothing to schedule. Remove the surveillance and the entire apparatus loses its inputs.

This is not a collection of tools. It is an architecture—a designed system where each component reinforces the others, creating a machine for automated control and killing.

---

## Human Rights Framework

The systems documented here raise fundamental questions under international humanitarian and human rights law.

### Privacy and Digital Rights

The mass interception of Palestinian communications—feeding both the Unit 8200 LLM and broader intelligence systems—violates the International Covenant on Civil and Political Rights (ICCPR) Article 17, which prohibits arbitrary interference with privacy, family, home, and correspondence.

Pegasus targeting of human rights defenders violates protections for freedom of expression (ICCPR Article 19) and association (Article 22), creating surveillance that chills legitimate civil society activity.

### Civilian Distinction and Proportionality

The decision support systems that accelerate targeting—Fire Factory scheduling strikes, Fire Weaver reducing engagement time to seconds—operate within a framework where documented error rates and permissive collateral damage thresholds suggest systematic failure to distinguish combatants from civilians.

When Fire Factory schedules strikes based on Lavender's outputs—a system sources say accepted error rates and civilian casualty ratios that permitted killing uninvolved family members—the automation does not remove responsibility. It distributes it across a system designed to minimize deliberation.

### Corporate Complicity

Under the UN Guiding Principles on Business and Human Rights, corporations have a responsibility to respect human rights, including conducting due diligence to identify and address adverse impacts.

Google and Amazon's provision of cloud infrastructure enabling these systems—despite documented military use, worker protests, and human rights organization warnings—constitutes a failure of due diligence. The retaliatory firing of workers who raised these concerns demonstrates active resistance to accountability.

NSO Group's licensing by the Israeli Ministry of Defense and documented use of Pegasus against human rights defenders establishes corporate complicity in surveillance that facilitates persecution of civil society.

---

## Sources and Evidence Assessment

The evidence for these systems comes from several categories of sources with varying levels of verification:

### Intelligence Source Testimony (High Credibility, Limited Verifiability)

Investigations by +972 Magazine and Local Call rely on testimonies from current and former Israeli intelligence and military personnel. These sources provide operational details unavailable through other means but cannot be independently verified. The consistency of accounts across multiple sources and their alignment with observable outcomes (documented strike patterns, system capabilities marketed by manufacturers) supports their credibility.

### Forensic Technical Analysis (High Credibility, High Verifiability)

Citizen Lab and Amnesty International's Security Lab provide technical forensics documenting Pegasus infections. These findings are verifiable through independent analysis and have been confirmed across multiple investigations.

### Corporate Disclosures and Marketing Materials (High Credibility for Capabilities)

Rafael, Elbit Systems, and other contractors publish marketing materials describing system capabilities. These sources are self-interested but reliable for understanding what systems are designed to do.

### Human Rights Documentation (High Credibility)

Reports from Human Rights Watch, Amnesty International, Front Line Defenders, Al-Haq, Addameer, Bisan Center, and 7amleh document impacts on Palestinian populations. These organizations maintain rigorous documentation standards and are subject to peer scrutiny.

### Government and Contract Documentation (Variable)

Project Nimbus contract details have been partially revealed through worker whistleblowing and investigative journalism. Official Israeli government statements about system capabilities should be treated as self-serving but useful for understanding official narratives.

---

*[← Part 4: The Wolf Pack](/research/algorithmic-kill-chain/facial-recognition/)* | *[Series Index](/research/algorithmic-kill-chain/)*

---

## Works Cited

### Human Rights Documentation

- Amnesty International. "Pegasus Spyware Surveillance Continues." 2023. https://amnesty.ca/human-rights-news/pegasus-spyware-surveillance-continues/
- Amnesty International. "Stand with the Six: End Israeli Apartheid." 2022. https://amnesty.ca/activism-guide/crisis-and-tactical-round-up-stand-with-the-six-end-israeli-apartheid-pegasus-targeted-surveillance-of-human-rights-defenders/
- Front Line Defenders. "Statement on Targeting of Palestinian HRDs with Pegasus." 2021. https://www.frontlinedefenders.org/en/statement-report/statement-targeting-palestinian-hrds-pegasus
- Front Line Defenders. "Action Needed to Address Targeted Surveillance of Human Rights Defenders." 2022. https://www.frontlinedefenders.org/en/statement-report/action-needed-address-targeted-surveillance-human-rights-defenders
- Human Rights Watch. "Among Pegasus Spyware Targets." January 2022. https://www.hrw.org/news/2022/01/26/human-rights-watch-among-pegasus-spyware-targets
- Human Rights Watch. "Questions and Answers: Israeli Military's Use of Digital Tools in Gaza." September 2024. https://www.hrw.org/news/2024/09/10/questions-and-answers-israeli-militarys-use-digital-tools-gaza
- 7amleh - Arab Center for Social Media Advancement. "7 Human Rights Organizations Condemn Use of NSO Group's Pegasus Against Palestinian Activists." 2021. https://7amleh.org/post/7-human-rights-organizations-condemn-use-of-nso-group-s-pegasus-against-palestinian-activists
- 7amleh. "Joint NGO Letter Urging EU Targeted Sanctions Against NSO Group." December 2021. https://7amleh.org/2021/12/03/joint-ngo-letter-urging-eu-targeted-sanctions-against-nso-group
- 7amleh. Digital Violence: Gaza Report. 2024. https://7amleh.org/storage/genocide/English%20new%20(1).pdf

### Investigative Journalism

- +972 Magazine. "Israeli Intelligence is Building a ChatGPT-like Surveillance Tool." 2024. https://www.972mag.com/israeli-intelligence-chatgpt-8200-surveillance-ai/
- +972 Magazine. "Armed Drones and Automated Killing of Palestinians." 2024. https://www.972mag.com/armed-drones-automated-killing-palestinians/
- Al Jazeera. "AI-Assisted Genocide: Israel Reportedly Used Database for Gaza Kill Lists." April 2024. https://www.aljazeera.com/news/2024/4/4/ai-assisted-genocide-israel-reportedly-used-database-for-gaza-kill-lists
- Al Jazeera. "What is Project Nimbus and Why Are Google Workers Protesting?" April 2024. https://www.aljazeera.com/news/2024/4/23/what-is-project-nimbus-and-why-are-google-workers-protesting-israel-deal
- Anadolu Agency. "How is Israel Using Artificial Intelligence in Its Deadly Attacks on Gaza?" 2024. https://www.aa.com.tr/en/middle-east/how-is-israel-using-artificial-intelligence-in-its-deadly-attacks-on-gaza/3088949
- Anadolu Agency. "Israel's AI System Used in Gaza Attacks Has Decades of History." 2024. https://www.aa.com.tr/en/middle-east/israels-ai-system-used-in-gaza-attacks-has-decades-of-history-report/3438296
- Electronic Intifada. "Campaign Against Project Nimbus Gathers Steam and Supporters." 2024. https://electronicintifada.net/content/campaign-against-project-nimbus-gathers-steam-and-supporters/48471
- Middle East Eye. "Israel's Use of AI in Gaza: A Terrifying Model Coming to a Country Near You." 2024. https://www.middleeasteye.net/opinion/israel-use-ai-gaza-terrifying-model-coming-country-near-you
- Middle East Eye. "Pegasus: Why Israel and Saudi Arabia Targeted Spyware." 2021. https://www.middleeasteye.net/opinion/pegasus-israel-saudi-arabia-why-targeted-spyware
- New Arab. "Gospel: Israel's Controversial AI Used in Gaza War." 2024. https://www.newarab.com/analysis/gospel-israels-controversial-ai-used-gaza-war
- NDTV. "How AI is Leading Israel's Bombing Campaign in Gaza." 2024. https://www.ndtv.com/world-news/israel-gaza-war-explained-how-ai-is-leading-israels-bombing-campaign-in-gaza-6448734
- OPB. "Israel AI Warfare Gaza Gospel." December 2023. https://www.opb.org/article/2023/12/14/israel-ai-warfare-gaza-gospel/
- PBS Frontline. "Global Spyware Scandal: Exposing Pegasus." Transcript. https://www.pbs.org/wgbh/frontline/documentary/global-spyware-scandal-exposing-pegasus/transcript/
- Seattle Times. "Report: 6 Palestinian Rights Activists Hacked by NSO Spyware." 2021. https://www.seattletimes.com/business/report-6-palestinian-rights-activists-hacked-by-nso-spyware/
- Time. "Exclusive: No Tech for Apartheid Google Workers Protest Project Nimbus." 2024. https://time.com/6964364/exclusive-no-tech-for-apartheid-google-workers-protest-project-nimbus-1-2-billion-contract-with-israel/
- Time. "Google Fires Workers Protesting Israeli Contract Project Nimbus." 2024. https://time.com/6968385/google-fires-workers-protesting-israeli-contract-project-nimbus/
- Transnational Institute. "All Roads Lead to Jerusalem." 2024. https://www.tni.org/en/article/all-roads-lead-to-jerusalem
- Transnational Institute. "Seeing the World Like a Palestinian." 2024. https://www.tni.org/en/article/seeing-the-world-like-a-palestinian
- TRT World. "How Israel's AI Use is Resulting in Indiscriminate Civilian Deaths in Gaza." 2024. https://www.trtworld.com/middle-east/how-israels-ai-use-is-resulting-in-indiscriminate-civilian-deaths-in-gaza-16057601
- Truthout. "Report: Israeli Army Uses AI to Produce Palestinian Targets for Assassination." 2024. https://truthout.org/articles/report-israeli-army-uses-ai-to-produce-palestinian-targets-for-assassination/

### Corporate and Defense Industry Sources

- C4ISRNET. Israel coverage. https://www.c4isrnet.com/tags/israel/
- Defense Update. "Fire Weaver." February 2020. https://defense-update.com/20200203_fireweaver.html
- Defense Update. "AFV Situational Awareness in the Urban Battlespace." June 2024. https://defense-update.com/20240620_afv-situational-awareness-in-the-urban-battlespace.html
- Military Periscope. "Rafael." https://www.militaryperiscope.com/defense-companies/rafael/
- Business & Human Rights Resource Centre. "USA: Google Fires 28 Employees Who Protested Its Project Nimbus Contract with Israel." 2024. https://www.business-humanrights.org/my/news/usa-google-fires-28-employees-who-protested-its-project-nimbus-contract-with-israel-incl-co-comments/
- Business & Human Rights Resource Centre. "Israel/OPT: Israeli Military Reservists Using Expertise Gained at Google, Meta, and Microsoft to Create Vast AI Surveillance Tool." 2024. https://www.business-humanrights.org/it/ultime-notizie/israelopt-israeli-military-reservists-using-expertise-gained-at-google-meta-and-microsoft-to-create-vast-ai-surveillance-tool/
- Courthouse News. "Google Employees Claim They Were Unlawfully Fired After Palestine Demonstration." 2024. https://www.courthousenews.com/google-employees-claim-they-were-unlawfully-fired-after-palestine-demonstration/
- Fox 13 Seattle. "Seattle Google Workers Protest Israeli Military Contracts." 2024. https://www.fox13seattle.com/news/seattle-google-workers-protest-israeli-military-contracts
- InfluenceWatch. "No Tech for Apartheid." https://www.influencewatch.org/organization/no-tech-for-apartheid/

### Academic and Policy Analysis

- Georgetown Security Studies Review. "The Dehumanization of ISR: Israel's Use of Artificial Intelligence in Warfare." January 2025. https://georgetownsecuritystudiesreview.org/2025/01/09/the-dehumanization-of-isr-israels-use-of-artificial-intelligence-in-warfare/
- ICRC Law and Policy Blog. "The Problem of Algorithmic Bias in AI-Based Military Decision Support Systems." September 2024. https://blogs.icrc.org/law-and-policy/2024/09/03/the-problem-of-algorithmic-bias-in-ai-based-military-decision-support-systems/
- ICRC Law and Policy Blog. "The Risks and Inefficacies of AI Systems in Military Targeting Support." September 2024. https://blogs.icrc.org/law-and-policy/2024/09/04/the-risks-and-inefficacies-of-ai-systems-in-military-targeting-support/
- Impact Policies. "Occupied Palestine: AI and Indiscriminate Targeting." 2024. https://impactpolicies.org/news/359/occupied-palestine-ai-and-indiscriminate-targeting
- Institute for Advanced International Studies. "Defense AI and Arms Control Network." 2024. http://www.defense-ai-and-arms-control.network/article?article_id=1680&article_language=en
- Italian Institute for International Affairs. IAI Paper 21/15. 2021. https://www.iai.it/sites/default/files/iai2115.pdf
- Jacobin. "Israel Gaza AI War Crimes." July 2024. https://jacobin.com/2024/07/israel-gaza-ai-war-crimes
- JINSA. "Israel Built an AI Factory for War. It Unleashed It in Gaza." 2024. https://jinsa.org/israel-built-an-ai-factory-for-war-it-unleashed-it-in-gaza/
- JINSA. "Man Replaced by Machine: Is the Use of AI Undermining the IDF's Intelligence Capabilities?" 2024. https://jinsa.org/man-replaced-by-machine-is-the-use-of-ai-undermining-the-idfs-intelligence-capabilities/
- Lieber Institute, West Point. "Algorithms at War: Military AI in the War in Gaza." 2024. https://lieber.westpoint.edu/algorithms-war-military-ai-war-gaza/
- Lieber Institute, West Point. "Gospel, Lavender, and the Law of Armed Conflict." 2024. https://lieber.westpoint.edu/gospel-lavender-law-armed-conflict/
- Opinio Juris. "Symposium on Military AI: The Need for Speed—The Cost of Unregulated AI Decision Support Systems to Civilians." April 2024. http://opiniojuris.org/2024/04/04/symposium-on-military-ai-and-the-law-of-armed-conflict-the-need-for-speed-the-cost-of-unregulated-ai-decision-support-systems-to-civilians/
- Palestine Studies. Digital edition. 2024. https://www.palestine-studies.org/en/node/1656285
- Ploughshares. "AI Targeting in Gaza and Beyond." 2024. https://www.ploughshares.ca/publications/ai-targeting-in-gaza-and-beyond
- Politics & Rights Review. "Sacred Violence: Military AI, Israel, Palestine." 2024. https://politicsrights.com/sacred-violence-military-ai-israel-palestine/
- RSIS Singapore. "IP24063: The Case for AI-Based Decision Support Systems Oversight." 2024. https://rsis.edu.sg/rsis-publication/idss/ip24063-the-case-for-ai-based-decision-support-systems-oversight/
- RUSI. "Israel Defense Forces' Use of AI in Gaza: A Case of Misplaced Purpose." 2024. https://rusi.org/explore-our-research/publications/commentary/israel-defense-forces-use-ai-gaza-case-misplaced-purpose
- Signal Magazine/AFCEA. "Targeting Tomorrow: The Intersection of AI and Military Operations." 2024. https://www.afcea.org/signal-media/international/targeting-tomorrow-intersection-ai-and-military-operations
- University of Edinburgh. "Rights to Privacy and Data Protection in Armed Conflict." 2022. https://www.pure.ed.ac.uk/ws/files/328308242/01708406221131938.pdf

### Legal and Government Sources

- Abolitionist Law Center. "Submission to UN Special Rapporteur on the Situation of Palestine." December 2024. https://abolitionistlawcenter.org/wp-content/uploads/2024/12/Abolitionist-Law-Center-Submission-to-UN-Special-Rapporteur-on-the-Situation-of-Palestine.pdf
- AP News. "Jordan Hacking Pegasus Spyware NSO Group." 2022. https://apnews.com/article/jordan-hacking-pegasus-spyware-nso-group-99b0b1e4ee256e0b4df055f926349a43
- Arab Center Washington DC. "The Full Story Behind the NSO Hack: The Israeli Military-Allied Surveillance Industry and Transnational Repression." 2021. https://arabcenterdc.org/resource/the-full-story-behind-the-nso-hack-the-israeli-military-allied-surveillance-industry-and-transnational-repression/
- Citizen Lab. "Litigation and Other Formal Complaints Concerning Targeted Digital Surveillance and the Digital Surveillance Industry." December 2018. https://citizenlab.ca/2018/12/litigation-and-other-formal-complaints-concerning-targeted-digital-surveillance-and-the-digital-surveillance-industry/
- CCDCOE. "The Rights to Privacy and Data Protection in Armed Conflict." 2022. https://ccdcoe.org/uploads/2022/06/The-Rights-to-Privacy-and-Data-Protection-in-Armed-Conflict.pdf
- European Parliament. EXPO_IDA(2024)754450. 2024. https://www.europarl.europa.eu/RegData/etudes/IDAN/2024/754450/EXPO_IDA(2024)754450_EN.pdf
- FMEP. "Top News on Israel-Palestine." 2024. https://fmep.org/blog/resourcecat/top-news-on-israel-palestine/
- George Washington University. Scholarly paper on military AI. https://scholarspace.library.gwu.edu/downloads/sq87bv679?disposition=inline&locale=en
- Wikipedia. "AI-Assisted Targeting in the Gaza Strip." https://en.wikipedia.org/wiki/AI-assisted_targeting_in_the_Gaza_Strip
- Wikipedia. "Pegasus (spyware)." https://en.wikipedia.org/wiki/Pegasus_(spyware)

### Additional Industry Documentation

- Digital Rosh. "Embracing the Organized Mess: DAI Israel." June 2023. https://digitalrosh.com/wp-content/uploads/2023/06/Embracing-the-Organized-Mess-DAI-Israel.pdf

---

*This research is part of [The Algorithmic Kill Chain](/research/algorithmic-kill-chain/) series documenting AI systems used in Israeli military operations. For questions or to request additional documentation, contact joshuaphilipdunlap@gmail.com.*