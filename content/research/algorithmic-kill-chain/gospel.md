+++
date = '2026-01-26'
draft = false
title = "Part 2: The Gospel — Automating Structural Destruction"
summary = "How Habsora generates 100+ building targets daily"
description = "The automated infrastructure targeting system generating bombing sites faster than humans can verify"
series = ['The Algorithmic Kill Chain']
series_order = 2
toc = true
hiddenInHomeList = true
+++

**The numbers that define automated urbicide:**

| Metric | Value | Source |
|:-------|------:|:-------|
| Manual target generation (pre-AI) | ~50/year | IDF historical baseline |
| Habsora target generation (2021) | 100/day | Former IDF Chief Aviv Kohavi |
| Habsora target generation (post-Oct 7) | 100-250+/day | Intelligence sources |
| Targets struck in first 35 days | ~15,000 | IDF reporting |
| Buildings destroyed across Gaza | 50%+ | UN/satellite analysis |

Before AI, identifying 50 targets took Israeli intelligence analysts a full year. Habsora now generates that volume before lunch.

---

## What Habsora Does

While [Lavender](/research/algorithmic-kill-chain/lavender/) marks individuals for assassination, Habsora marks structures for demolition. The Gospel is the IDF's AI system for automating the identification of buildings, infrastructure, tunnels, and homes deemed "significant" by algorithmic analysis.

Developed by the IDF's Targets Administration Division (established 2019), the system processes surveillance data—drone footage, intercepted communications, cell phone tracking, geospatial intelligence—and outputs coordinates for bombing.

The critical insight: Habsora doesn't merely *find* targets. It algorithmically *constructs* them. The system operates through pattern-matching, comparing new data against characteristics of structures previously designated as "militant-affiliated." A building showing sufficient statistical correlation gets flagged for destruction.

This is probabilistic inference, not causal evidence. As AI researchers consistently warn, such systems recommend targets based on correlations in training data—data gathered through decades of occupation surveillance, framed entirely by Israeli security paradigms. The algorithm inherits the colonial gaze that views Palestinian infrastructure as inherently suspect.

---

## The Target Categories

Habsora generates recommendations across Gaza's entire built environment:

### "Operatives' Homes"

The private residences of individuals suspected of militant affiliation—extended under post-October 7 policies to include junior operatives previously considered off-limits. One source described the practice bluntly: "So they mark the home and bomb the house and kill everyone there."

The system reportedly calculates expected civilian casualties for each target. These calculations feed into "proportionality" decisions made under rules of engagement that were drastically loosened after October 7.

### "Power Targets"

This category reveals the underlying doctrine most clearly. "Power targets" include:

- High-rise apartment buildings
- Residential towers
- Universities
- Banks
- Government ministry buildings
- Mosques

Intelligence sources explicitly state the purpose: not immediate military advantage, but to inflict harm on Palestinian civil society, create "shock," and exert "civil pressure" on Hamas. This is the [Dahiya Doctrine](https://en.wikipedia.org/wiki/Dahiya_doctrine) encoded into software—disproportionate force against civilian infrastructure as deliberate strategy.

The bombing of the Babel Building, Al-Taj tower, Al-Mohandseen tower, and the Islamic University of Gaza all fall within this category.

### Tactical and Underground Targets

Alleged command posts, weapons storage, rocket launch sites, and tunnel infrastructure. These categories are presented as legitimate military objectives, though the speed of Habsora's generation and the minimal review process raise serious questions about verification.

---

## The Integration: How Lavender and Habsora Work Together

The systems don't operate in isolation. They create a synergistic kill chain:

1. **Habsora** identifies a residential building as a potential target based on algorithmic analysis
2. **Lavender** flags an individual on its kill list as present in that building
3. **"Where's Daddy?"** tracks the individual until they return home—preferably at night, when family is gathered
4. The home becomes the strike coordinates

This convergence transforms Palestinian homes from potential sanctuaries into preferred kill zones. The operational logic appears calibrated not merely to eliminate the targeted individual, but to do so when and where family casualties are maximized.

The integration is deliberate. The systems were designed to work together. The "Where's Daddy?" nickname—chosen by IDF personnel—indicates awareness of what the system does: it waits for fathers to come home to their children before triggering the strike.

---

## The Velocity Problem

Former IDF Chief of Staff Aviv Kohavi publicly celebrated the transformation: where analysts once identified 50 targets across an entire year, Habsora generates 100 per day.

**What this velocity enables:**

- First 35 days post-October 7: approximately 15,000 targets struck
- Comparison: 51-day 2014 assault struck 5,263 targets total
- The system produces recommendations faster than the Air Force can act on them

Target scarcity is no longer a limiting factor. The pipeline is infinite.

---

## Legal Analysis: Systematic Violations

### Distinction

The IHL principle of distinction prohibits attacks on civilian objects. It requires attackers to verify that a structure contributes to military action before targeting.

Habsora inverts verification. The system generates targets based on correlational analysis—not confirmed military use. The speed of its output precludes meaningful human verification. The inclusion of "power targets"—civilian infrastructure targeted explicitly for psychological effect—directly violates distinction.

### Proportionality

Even legitimate military targets may only be attacked if expected civilian harm doesn't exceed military advantage. The evidence suggests systematic violation:

- The system calculates expected civilian casualties
- Post-October 7 rules permit strikes anticipated to kill dozens or hundreds of civilians to eliminate single targets (sometimes junior operatives)
- The scale of civilian death demonstrates that anticipated military gains routinely "outweigh" devastating, foreseeable harm

This is not risk tolerance. This is policy.

### Precautions

Parties must take feasible precautions to minimize civilian harm. Habsora's operational tempo directly undermines this obligation:

- Rapid target generation leaves insufficient time for verifying civilian absence
- Reports indicate residential buildings struck without prior warning
- The system's velocity is structurally incompatible with meaningful precautionary measures

---

## The Accountability Void

When destruction is mediated through opaque algorithms, rapid queues, and perfunctory review, who bears responsibility for unlawful strikes?

The algorithm's designers? The commanders who approve policies? The operators who rubber-stamp recommendations? The political leadership that deployed the system?

Habsora's architecture distributes responsibility across so many nodes that no single point becomes accountable. This diffusion is not incidental—it's a feature that enables the commission of potential atrocity crimes while providing plausible deniability at every level.

---

## The Broader Framework

Habsora cannot be understood solely through international humanitarian law. It functions within structures of:

**Settler Colonialism:** Mass destruction of homes (domicide) and urban landscapes (urbicide) directly facilitates displacement of indigenous population and seizure of land.

**Apartheid:** The system is part of a technologically advanced apparatus of surveillance, control, and violence deployed overwhelmingly against one racialized group—reinforcing segregation, domination, and differential rights.

**Potential Genocide:** Given inflammatory rhetoric from Israeli officials, the catastrophic civilian death toll, and systematic destruction of infrastructure essential for sustaining life, Habsora's role in facilitating these outcomes is deeply concerning. The system enables what the Genocide Convention prohibits: "deliberately inflicting on the group conditions of life calculated to bring about its physical destruction."

AI in this context is not a neutral force multiplier. It accelerates and scales state violence, making the commission of potential atrocity crimes technologically feasible and bureaucratically streamlined.

---

## Challenging the Official Narrative

The IDF emphasizes precision, adherence to international law, robust human control, minimization of civilian harm.

The evidence reveals: mass target generation, loosened casualty constraints, perfunctory review, and deliberate targeting of civilian infrastructure for "civil pressure."

Attempts to downplay AI's role—characterizing systems as mere "databases" or claiming AI *improves* accuracy—appear as strategic efforts to maintain plausible deniability. The deliberate opacity surrounding Habsora's algorithms, data inputs, and operational parameters serves a clear purpose: hinder independent scrutiny and deflect accountability while leveraging the perception of technological sophistication.

---

## Works Cited

### Primary Investigative Sources

1. [+972 Magazine and Local Call - "Lavender": The AI Machine Directing Israel's Bombing Spree in Gaza](https://www.972mag.com/lavender-ai-israeli-army-gaza/)
2. [+972 Magazine - A Mass Assassination Factory: Inside Israel's Calculated Bombing of Gaza](https://www.972mag.com/mass-assassination-factory-israel-calculated-bombing-gaza/)
3. [The Guardian - "The Machine Did It Coldly": Israel Used AI to Identify 37,000 Hamas Targets](https://www.theguardian.com/world/2024/apr/03/israel-gaza-ai-database-hamas-targets)

### Human Rights Documentation

4. [Human Rights Watch - Questions and Answers: Israeli Military's Use of Digital Tools in Gaza](https://www.hrw.org/news/2024/09/10/questions-and-answers-israeli-militarys-use-digital-tools-gaza)
5. [Amnesty International - Israel/OPT: Unprecedented Destruction in Gaza](https://www.amnesty.org/en/latest/news/2024/01/israel-opt-unprecedented-destruction-gaza/)
6. [Access Now - Digital Rights in Gaza Under Attack](https://www.accessnow.org/)

### IDF Statements and Analysis

7. [Ynet - Aviv Kohavi on AI Target Generation](https://www.ynet.co.il/)
8. [IDF Spokesperson - Official Statements on Targeting](https://www.idf.il/)

### Legal and Academic Analysis

9. [Opinio Juris - The Need for Speed: The Cost of Unregulated AI Decision Support Systems to Civilians](http://opiniojuris.org/2024/04/04/symposium-on-military-ai-and-the-law-of-armed-conflict-the-need-for-speed-the-cost-of-unregulated-ai-decision-support-systems-to-civilians/)
10. [RUSI - Israel Defense Forces' Use of AI in Gaza: A Case of Misplaced Purpose](https://rusi.org/explore-our-research/publications/commentary/israel-defense-forces-use-ai-gaza-case-misplaced-purpose)

### News Coverage

11. [Al Jazeera - AI-Assisted Genocide: Israel Reportedly Used Database for Gaza Kill Lists](https://www.aljazeera.com/news/2024/4/4/ai-assisted-genocide-israel-reportedly-used-database-for-gaza-kill-lists)
12. [New Arab - Gospel: Israel's Controversial AI Used in Gaza War](https://www.newarab.com/analysis/gospel-israels-controversial-ai-used-gaza-war)
13. [OPB - Israel AI Warfare Gaza Gospel](https://www.opb.org/article/2023/12/14/israel-ai-warfare-gaza-gospel/)

### UN Documentation

14. [UN OCHA - Gaza Strip: Humanitarian Situation Update](https://www.ochaopt.org/)
15. [UN Satellite Analysis - Gaza Destruction Assessment](https://unosat.org/)

---

*Next: [Part 3: Where's Daddy?](/research/algorithmic-kill-chain/wheres-daddy/) — How tracking technology transformed family homes into preferred kill zones*

---

**[← Previous: Lavender](/research/algorithmic-kill-chain/lavender/)** · **[Series Index](/research/algorithmic-kill-chain/)** · **[Next: Where's Daddy? →](/research/algorithmic-kill-chain/wheres-daddy/)**

---

*This investigation is part of [The Algorithmic Kill Chain](/research/algorithmic-kill-chain/) series documenting AI-enabled targeting systems. For questions or additional documentation, contact joshuaphilipdunlap@gmail.com.*